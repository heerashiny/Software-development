import requests
from bs4 import BeautifulSoup
import csv

def scrape_books():
    url = "http://books.toscrape.com/catalogue/page-1.html"
    products = []

    while url:
        print(f"Scraping {url}")
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')

        for book in soup.select('.product_pod'):
            title = book.h3.a['title']
            price = book.select_one('.price_color').text.strip()
            rating_class = book.select_one('.star-rating')['class']
            rating = rating_class[1]  # like 'Three', 'Four'

            products.append({
                'Title': title,
                'Price': price,
                'Rating': rating
            })

        next_button = soup.select_one('li.next > a')
        if next_button:
            next_page = next_button['href']
            url = "http://books.toscrape.com/catalogue/" + next_page
        else:
            url = None

    # Save to CSV
    with open('products.csv', 'w', newline='', encoding='utf-8') as csvfile:
        fieldnames = ['Title', 'Price', 'Rating']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for product in products:
            writer.writerow(product)

    print("Scraping complete. Data saved to 'products.csv'.")

# Run the scraper
scrape_books()
